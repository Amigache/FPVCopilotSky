# üöÄ Estrategia CI/CD para FPV Copilot Sky

Este documento describe la estrategia de **Continuous Integration** y **Continuous Deployment** para FPV Copilot Sky, considerando los desaf√≠os √∫nicos del proyecto: hardware embebido, dependencias de sistema (GStreamer, NetworkManager), arquitectura ARM, y dispositivos externos (modem, FC, c√°mara).

---

## üìã Tabla de contenidos

- [Objetivos](#-objetivos)
- [CI - Continuous Integration](#-ci---continuous-integration)
  - [Lint y Formato](#1-lint-y-formato)
  - [Tests Backend](#2-tests-backend)
  - [Tests Frontend](#3-tests-frontend)
  - [Build Frontend](#4-build-frontend)
  - [Security Scan](#5-security-scan)
- [CD - Continuous Deployment](#-cd---continuous-deployment)
  - [Deploy a Staging](#deploy-a-staging)
  - [Release Automation](#release-automation)
- [Testing Strategy](#-testing-strategy)
  - [Mocks para Hardware](#mocks-para-hardware-dependencies)
  - [Tests a Implementar](#tests-a-implementar)
- [Artifacts y Distribuci√≥n](#-artifacts-y-distribuci√≥n)
- [Local Development](#-local-development-helpers)
- [Badges y M√©tricas](#-badges-para-readme)
- [Roadmap de Implementaci√≥n](#-roadmap-de-implementaci√≥n)

---

## üéØ Objetivos

| Objetivo               | Descripci√≥n                                        |
| ---------------------- | -------------------------------------------------- |
| **Calidad de c√≥digo**  | Lint, formato y type checking autom√°tico           |
| **Testing autom√°tico** | Tests unitarios e integraci√≥n en cada PR           |
| **Build validation**   | Validar que el frontend se construye correctamente |
| **Security**           | Escaneo de vulnerabilidades en dependencias        |
| **Deploy autom√°tico**  | Deploy a staging en cada merge a `main`            |
| **Releases**           | Generaci√≥n autom√°tica de packages y changelogs     |
| **Feedback r√°pido**    | Resultados de CI en <5 minutos                     |

---

## üîÑ CI - Continuous Integration

Pipeline ejecutado en **cada Pull Request** y **push a main/develop**.

### 1. Lint y Formato

#### Backend (Python)

```yaml
# .github/workflows/ci.yml
lint-backend:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: "3.12"

    - name: Install dependencies
      run: |
        pip install flake8 black mypy
        pip install -r requirements.txt

    - name: Lint with flake8
      run: flake8 app/ --max-line-length=120 --exclude=__pycache__

    - name: Check formatting with black
      run: black --check app/

    - name: Type check with mypy
      run: mypy app/ --ignore-missing-imports --no-strict-optional
```

**Reglas de lint:**

- `flake8`: PEP 8 compliance, max line length 120
- `black`: Consistent formatting style
- `mypy`: Type hints validation

#### Frontend (JavaScript/React)

```yaml
lint-frontend:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: "20"

    - name: Install dependencies
      working-directory: frontend/client
      run: npm ci

    - name: Lint with ESLint
      working-directory: frontend/client
      run: npm run lint

    - name: Check formatting with Prettier
      working-directory: frontend/client
      run: npx prettier --check src/
```

**Reglas de lint:**

- `ESLint`: React best practices, hooks rules
- `Prettier`: Consistent code formatting

### 2. Tests Backend

```yaml
test-backend:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v5
      with:
        python-version: "3.12"

    - name: Install dependencies
      run: |
        pip install pytest pytest-asyncio pytest-cov pytest-mock
        pip install -r requirements.txt

    - name: Run unit tests
      run: |
        pytest tests/ \
          --cov=app \
          --cov-report=xml \
          --cov-report=html \
          --cov-report=term \
          -v \
          --tb=short

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./coverage.xml
        flags: backend
        name: backend-coverage

    - name: Check coverage threshold
      run: |
        COVERAGE=$(grep -oP 'line-rate="\K[0-9.]+' coverage.xml | head -1)
        THRESHOLD=0.70
        if (( $(echo "$COVERAGE < $THRESHOLD" | bc -l) )); then
          echo "Coverage $COVERAGE is below threshold $THRESHOLD"
          exit 1
        fi
```

**Test requirements:**

- Minimum 70% code coverage
- All tests must pass
- Mock external dependencies (serial, modem, GStreamer)

### 3. Tests Frontend

```yaml
test-frontend:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: "20"

    - name: Install dependencies
      working-directory: frontend/client
      run: npm ci

    - name: Run unit tests
      working-directory: frontend/client
      run: npm run test -- --coverage --run

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      with:
        file: ./frontend/client/coverage/coverage-final.json
        flags: frontend
        name: frontend-coverage
```

**Test framework:**

- `Vitest` for unit tests
- `@testing-library/react` for component testing
- Coverage target: >60%

### 4. Build Frontend

```yaml
build-frontend:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: "20"

    - name: Install dependencies
      working-directory: frontend/client
      run: npm ci

    - name: Build production bundle
      working-directory: frontend/client
      run: npm run build

    - name: Check bundle size
      working-directory: frontend/client
      run: |
        SIZE=$(du -sm dist | cut -f1)
        if [ $SIZE -gt 5 ]; then
          echo "Bundle size ${SIZE}MB exceeds 5MB limit"
          exit 1
        fi

    - name: Upload build artifacts
      uses: actions/upload-artifact@v4
      with:
        name: frontend-dist
        path: frontend/client/dist/
        retention-days: 7
```

**Build validation:**

- Bundle size must be <5MB
- No build errors or warnings
- Assets are properly optimized

### 5. Security Scan

```yaml
security-scan:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: "fs"
        scan-ref: "."
        format: "sarif"
        output: "trivy-results.sarif"
        severity: "CRITICAL,HIGH"

    - name: Upload Trivy results to GitHub Security
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: "trivy-results.sarif"

    - name: Python security check with Safety
      run: |
        pip install safety
        safety check --json --output safety-report.json || true

    - name: Node.js security audit
      working-directory: frontend/client
      run: npm audit --audit-level=high
```

**Security checks:**

- Trivy: Scan for vulnerabilities in dependencies
- Safety: Python package vulnerabilities
- npm audit: JavaScript package vulnerabilities

---

## üì¶ CD - Continuous Deployment

### Deploy a Staging

Ejecutado autom√°ticamente en **merge a `main`**.

```yaml
# .github/workflows/deploy-staging.yml
name: CD - Deploy to Staging

on:
  push:
    branches: [main]

jobs:
  deploy-staging:
    runs-on: ubuntu-latest
    environment: staging
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Build frontend
        working-directory: frontend/client
        run: |
          npm ci
          npm run build

      - name: Create deployment package
        run: |
          mkdir -p release
          tar -czf release/fpvcopilot-sky-staging.tar.gz \
            --exclude='__pycache__' \
            --exclude='*.pyc' \
            --exclude='venv' \
            --exclude='node_modules' \
            app/ \
            frontend/client/dist/ \
            scripts/ \
            systemd/ \
            requirements.txt \
            install.sh

      - name: Deploy to staging SBC via SSH
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.STAGING_HOST }}
          username: ${{ secrets.STAGING_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          port: ${{ secrets.STAGING_PORT }}
          script: |
            set -e
            echo "üöÄ Starting deployment to staging..."

            cd /opt/FPVCopilotSky

            # Backup current version
            sudo cp preferences.json preferences.json.backup || true

            # Pull latest code
            git fetch origin
            git reset --hard origin/main

            # Deploy
            sudo bash scripts/deploy.sh

            echo "‚úÖ Deployment complete"

      - name: Wait for service startup
        run: sleep 15

      - name: Health check
        run: |
          echo "üîç Checking health endpoint..."
          curl -f http://${{ secrets.STAGING_HOST }}/api/status || exit 1
          echo "‚úÖ Health check passed"

      - name: Smoke tests
        run: |
          # Test critical endpoints
          curl -f http://${{ secrets.STAGING_HOST }}/api/mavlink-router/outputs || exit 1
          curl -f http://${{ secrets.STAGING_HOST }}/api/video/sources || exit 1
          echo "‚úÖ Smoke tests passed"

      - name: Notify on failure
        if: failure()
        run: |
          curl -X POST ${{ secrets.DISCORD_WEBHOOK }} \
            -H 'Content-Type: application/json' \
            -d '{
              "content": "‚ùå Staging deployment failed!",
              "embeds": [{
                "title": "Deployment Failed",
                "description": "Check GitHub Actions for details",
                "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                "color": 15158332
              }]
            }'
```

**Staging environment:**

- Dedicated SBC (Radxa Zero or similar)
- Accessible via VPN or SSH tunnel
- Same configuration as production
- Database/preferences backed up before deploy

### Release Automation

Ejecutado en **push de tags** (`v*`).

````yaml
# .github/workflows/release.yml
name: Release - Create Package

on:
  push:
    tags:
      - "v*"

jobs:
  create-release:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Full history for changelog

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Build frontend for production
        working-directory: frontend/client
        run: |
          npm ci
          npm run build

      - name: Create release package
        run: |
          VERSION=${GITHUB_REF#refs/tags/v}
          echo "Creating release package for version $VERSION"

          mkdir -p release

          # Full package
          tar -czf release/fpvcopilot-sky-v${VERSION}.tar.gz \
            --exclude='venv' \
            --exclude='node_modules' \
            --exclude='.git' \
            --exclude='__pycache__' \
            --exclude='*.pyc' \
            --exclude='.DS_Store' \
            app/ \
            frontend/client/dist/ \
            scripts/ \
            systemd/ \
            docs/ \
            requirements.txt \
            pyproject.toml \
            install.sh \
            README.md \
            CONTRIBUTING.md \
            LICENSE

          # Checksums
          cd release
          sha256sum fpvcopilot-sky-v${VERSION}.tar.gz > checksums.txt
          md5sum fpvcopilot-sky-v${VERSION}.tar.gz >> checksums.txt

      - name: Generate changelog
        id: changelog
        uses: mikepenz/release-changelog-builder-action@v4
        with:
          configuration: |
            {
              "categories": [
                {
                  "title": "## üöÄ Features",
                  "labels": ["feat", "feature"]
                },
                {
                  "title": "## üêõ Bug Fixes",
                  "labels": ["fix", "bugfix"]
                },
                {
                  "title": "## üìö Documentation",
                  "labels": ["docs", "documentation"]
                },
                {
                  "title": "## üîß Refactor",
                  "labels": ["refactor"]
                },
                {
                  "title": "## ‚ö° Performance",
                  "labels": ["perf", "performance"]
                }
              ],
              "template": "#{{CHANGELOG}}\n\n**Full Changelog**: #{{RELEASE_DIFF}}"
            }
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          body: |
            # FPV Copilot Sky ${{ github.ref_name }}

            ${{ steps.changelog.outputs.changelog }}

            ## üì¶ Installation

            ```bash
            VERSION="${{ github.ref_name }}"
            wget https://github.com/${{ github.repository }}/releases/download/${VERSION}/fpvcopilot-sky-${VERSION}.tar.gz
            tar -xzf fpvcopilot-sky-${VERSION}.tar.gz -C /opt/FPVCopilotSky
            cd /opt/FPVCopilotSky
            sudo bash install.sh
            ```

            ## üîç Verify Download

            ```bash
            sha256sum -c checksums.txt
            ```
          files: |
            release/fpvcopilot-sky-*.tar.gz
            release/checksums.txt
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Notify Discord/Slack
        if: success()
        run: |
          VERSION=${GITHUB_REF#refs/tags/}
          curl -X POST ${{ secrets.DISCORD_WEBHOOK }} \
            -H 'Content-Type: application/json' \
            -d '{
              "content": "üöÄ **New Release Available!**",
              "embeds": [{
                "title": "FPV Copilot Sky '$VERSION'",
                "description": "A new version has been released",
                "url": "https://github.com/${{ github.repository }}/releases/tag/'$VERSION'",
                "color": 3447003,
                "fields": [
                  {
                    "name": "Version",
                    "value": "'$VERSION'",
                    "inline": true
                  },
                  {
                    "name": "Download",
                    "value": "[Release Page](https://github.com/${{ github.repository }}/releases/tag/'$VERSION')",
                    "inline": true
                  }
                ]
              }]
            }'
````

**Release artifacts:**

- Complete package with pre-built frontend
- Checksums (SHA256, MD5)
- Auto-generated changelog
- Installation instructions
- Discord/Slack notifications

---

## üß™ Testing Strategy

### Mocks para Hardware Dependencies

Dado que el CI no tiene acceso a hardware f√≠sico (FC, modem, c√°mara), necesitamos mocks comprehensivos.

#### Fixtures principales

```python
# tests/conftest.py
import pytest
from unittest.mock import Mock, patch, MagicMock
import json

@pytest.fixture
def mock_serial_port():
    """Mock pyserial for tests without hardware"""
    with patch('serial.Serial') as mock:
        mock_port = Mock()
        mock_port.is_open = True
        mock_port.in_waiting = 0
        mock_port.baudrate = 115200
        mock_port.port = '/dev/ttyUSB0'

        # Mock MAVLink heartbeat packet
        mock_port.read.return_value = b'\xfe\x09\x00\x01\x01\x00\x00\x00\x00\x00\x06\x08\x00\x00\x00\x03'

        mock.return_value = mock_port
        yield mock_port

@pytest.fixture
def mock_mavlink_connection():
    """Mock MAVLink connection"""
    with patch('pymavlink.mavutil.mavlink_connection') as mock:
        mock_conn = Mock()
        mock_conn.target_system = 1
        mock_conn.target_component = 1

        # Mock heartbeat message
        mock_heartbeat = Mock()
        mock_heartbeat.get_type.return_value = 'HEARTBEAT'
        mock_heartbeat.custom_mode = 0
        mock_heartbeat.base_mode = 81
        mock_heartbeat.system_status = 4

        mock_conn.recv_match.return_value = mock_heartbeat
        mock_conn.wait_heartbeat.return_value = True

        mock.return_value = mock_conn
        yield mock_conn

@pytest.fixture
def mock_hilink_modem():
    """Mock Huawei HiLink API"""
    with patch('huawei_lte_api.Connection') as mock:
        mock_conn = Mock()

        # Mock device info
        mock_conn.device.information.return_value = {
            'DeviceName': 'E3372h-320',
            'Imei': '123456789012345',
            'HardwareVersion': 'CL2E3372HM',
            'SoftwareVersion': '22.333.01.00.00'
        }

        # Mock signal info
        mock_conn.device.signal.return_value = {
            'rssi': '-65',
            'rsrp': '-95',
            'rsrq': '-10',
            'sinr': '15',
            'cell_id': '12345678'
        }

        # Mock network info
        mock_conn.net.current_plmn.return_value = {
            'FullName': 'Orange Spain',
            'ShortName': 'Orange',
            'Numeric': '21407'
        }

        mock.return_value = mock_conn
        yield mock_conn

@pytest.fixture
def mock_gstreamer():
    """Mock GStreamer for tests without camera"""
    with patch('gi.repository.Gst') as mock_gst:
        mock_pipeline = MagicMock()
        mock_pipeline.set_state.return_value = (True, 0, 0)
        mock_pipeline.get_state.return_value = (1, 4, 0)  # SUCCESS, PLAYING, VOID_PENDING

        mock_gst.Pipeline.return_value = mock_pipeline
        mock_gst.State.PLAYING = 4
        mock_gst.State.NULL = 1

        yield mock_gst

@pytest.fixture
def mock_subprocess():
    """Mock subprocess for system commands"""
    with patch('subprocess.run') as mock:
        mock_result = Mock()
        mock_result.returncode = 0
        mock_result.stdout = "Mock output"
        mock_result.stderr = ""
        mock.return_value = mock_result
        yield mock

@pytest.fixture
def temp_preferences(tmp_path):
    """Create temporary preferences file"""
    prefs_file = tmp_path / "preferences.json"
    prefs_data = {
        "serial": {
            "port": "/dev/ttyUSB0",
            "baudrate": 115200,
            "auto_connect": False
        },
        "video": {
            "source": "libcamera",
            "codec": "h264",
            "width": 1280,
            "height": 720,
            "fps": 30
        },
        "vpn": {
            "provider": "tailscale",
            "auto_connect": False
        }
    }
    prefs_file.write_text(json.dumps(prefs_data, indent=2))
    return prefs_file
```

### Tests a Implementar

#### Backend Tests

```python
# tests/test_mavlink_bridge.py
import pytest
from app.services.mavlink_bridge import MAVLinkBridge

@pytest.mark.asyncio
async def test_connect_success(mock_serial_port, mock_mavlink_connection):
    """Test successful MAVLink connection"""
    bridge = MAVLinkBridge()
    result = await bridge.connect("/dev/ttyUSB0", 115200)

    assert result["success"] is True
    assert bridge.is_connected() is True
    assert bridge.get_system_id() == 1

@pytest.mark.asyncio
async def test_connect_no_heartbeat(mock_serial_port, mock_mavlink_connection):
    """Test connection fails without heartbeat"""
    mock_mavlink_connection.wait_heartbeat.side_effect = TimeoutError()

    bridge = MAVLinkBridge()
    result = await bridge.connect("/dev/ttyUSB0", 115200)

    assert result["success"] is False
    assert "timeout" in result["message"].lower()

@pytest.mark.asyncio
async def test_disconnect(mock_mavlink_connection):
    """Test clean disconnection"""
    bridge = MAVLinkBridge()
    await bridge.connect("/dev/ttyUSB0", 115200)

    result = await bridge.disconnect()

    assert result["success"] is True
    assert bridge.is_connected() is False

# tests/test_preferences.py
from app.services.preferences import PreferencesService

def test_save_load_cycle(temp_preferences):
    """Test preferences are persisted correctly"""
    prefs = PreferencesService(config_path=str(temp_preferences))

    # Modify serial config
    prefs.set_serial_config(port="/dev/ttyUSB1", baudrate=57600)

    # Reload from disk
    prefs2 = PreferencesService(config_path=str(temp_preferences))
    config = prefs2.get_serial_config()

    assert config["port"] == "/dev/ttyUSB1"
    assert config["baudrate"] == 57600

def test_concurrent_access(temp_preferences):
    """Test thread-safe access with RLock"""
    prefs = PreferencesService(config_path=str(temp_preferences))

    # Simulate concurrent access
    import concurrent.futures

    def update_serial():
        prefs.set_serial_config(port="/dev/ttyUSB0", baudrate=115200)

    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(update_serial) for _ in range(10)]
        concurrent.futures.wait(futures)

    # Should not deadlock
    config = prefs.get_serial_config()
    assert config["port"] == "/dev/ttyUSB0"

# tests/test_modem_provider.py
from app.providers.modem.hilink.router import HuaweiHiLinkRouter

def test_get_status(mock_hilink_modem):
    """Test modem status retrieval"""
    provider = HuaweiHiLinkRouter()
    status = provider.get_status()

    assert status["available"] is True
    assert "signal" in status
    assert status["signal"]["rssi"] == "-65"

def test_get_band_presets(mock_hilink_modem):
    """Test band presets are returned"""
    provider = HuaweiHiLinkRouter()
    presets = provider.get_band_presets()

    assert "presets" in presets
    assert "all" in presets["presets"]
    assert "orange_spain" in presets["presets"]

# tests/test_video_service.py
from app.services.gstreamer_service import GStreamerService

@pytest.mark.asyncio
async def test_start_stream(mock_gstreamer):
    """Test video stream starts successfully"""
    service = GStreamerService()
    config = {
        "source": "libcamera",
        "codec": "h264",
        "width": 1280,
        "height": 720,
        "fps": 30,
        "bitrate": 2000
    }

    result = await service.start_stream(config)

    assert result["success"] is True
    assert service.is_streaming() is True

@pytest.mark.asyncio
async def test_stop_stream(mock_gstreamer):
    """Test video stream stops cleanly"""
    service = GStreamerService()
    await service.start_stream({})

    result = await service.stop_stream()

    assert result["success"] is True
    assert service.is_streaming() is False
```

#### Frontend Tests

```jsx
// frontend/client/src/components/__tests__/Header.test.jsx
import { render, screen } from "@testing-library/react";
import { BrowserRouter } from "react-router-dom";
import Header from "../Header/Header";

test("renders header title", () => {
  render(
    <BrowserRouter>
      <Header />
    </BrowserRouter>,
  );
  const title = screen.getByText(/FPV Copilot Sky/i);
  expect(title).toBeInTheDocument();
});

test("displays connection status", () => {
  render(
    <BrowserRouter>
      <Header streamOnline={true} fcConnected={true} />
    </BrowserRouter>,
  );

  expect(screen.getByText(/Stream: Online/i)).toBeInTheDocument();
  expect(screen.getByText(/FC Connected/i)).toBeInTheDocument();
});

// frontend/client/src/components/__tests__/TelemetryView.test.jsx
import { render, screen, waitFor } from "@testing-library/react";
import userEvent from "@testing-library/user-event";
import TelemetryView from "../Pages/TelemetryView";

test("loads and displays router outputs", async () => {
  global.fetch = vi.fn(() =>
    Promise.resolve({
      ok: true,
      json: () =>
        Promise.resolve([
          { id: 1, type: "udp", host: "0.0.0.0", port: 14550, active: true },
        ]),
    }),
  );

  render(<TelemetryView />);

  await waitFor(() => {
    expect(screen.getByText(/14550/)).toBeInTheDocument();
  });
});

test("creates new output", async () => {
  const user = userEvent.setup();

  global.fetch = vi.fn(() =>
    Promise.resolve({
      ok: true,
      json: () => Promise.resolve({ success: true }),
    }),
  );

  render(<TelemetryView />);

  await user.type(screen.getByLabelText(/Host/i), "192.168.1.100");
  await user.type(screen.getByLabelText(/Port/i), "5760");
  await user.click(screen.getByText(/Create/i));

  await waitFor(() => {
    expect(global.fetch).toHaveBeenCalledWith(
      expect.stringContaining("/outputs"),
      expect.objectContaining({ method: "POST" }),
    );
  });
});
```

---

## üì¶ Artifacts y Distribuci√≥n

### Estructura del Release Package

```
fpvcopilot-sky-v1.2.0.tar.gz
‚îú‚îÄ‚îÄ app/                          # Backend Python
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ providers/
‚îÇ   ‚îú‚îÄ‚îÄ i18n/
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îú‚îÄ‚îÄ frontend/client/dist/         # Frontend pre-built
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index-<hash>.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index-<hash>.css
‚îÇ   ‚îî‚îÄ‚îÄ favicon.ico
‚îú‚îÄ‚îÄ scripts/                      # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ install-production.sh
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh
‚îÇ   ‚îú‚îÄ‚îÄ dev.sh
‚îÇ   ‚îú‚îÄ‚îÄ status.sh
‚îÇ   ‚îî‚îÄ‚îÄ configure-modem.sh
‚îú‚îÄ‚îÄ systemd/                      # Service files
‚îÇ   ‚îú‚îÄ‚îÄ fpvcopilot-sky.service
‚îÇ   ‚îî‚îÄ‚îÄ fpvcopilot-sky.nginx
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ INSTALLATION.md
‚îÇ   ‚îú‚îÄ‚îÄ USER_GUIDE.md
‚îÇ   ‚îú‚îÄ‚îÄ DEVELOPER_GUIDE.md
‚îÇ   ‚îú‚îÄ‚îÄ BOARD_PROVIDER_SYSTEM.md
‚îÇ   ‚îî‚îÄ‚îÄ CI_CD_STRATEGY.md
‚îú‚îÄ‚îÄ requirements.txt              # Python dependencies
‚îú‚îÄ‚îÄ pyproject.toml               # Python project config
‚îú‚îÄ‚îÄ install.sh                   # Main installer
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îî‚îÄ‚îÄ LICENSE
```

### Instalaci√≥n desde Release

```bash
# Download latest release
VERSION="1.2.0"
wget https://github.com/user/FPVCopilotSky/releases/download/v${VERSION}/fpvcopilot-sky-v${VERSION}.tar.gz

# Verify checksum
wget https://github.com/user/FPVCopilotSky/releases/download/v${VERSION}/checksums.txt
sha256sum -c checksums.txt

# Extract
sudo mkdir -p /opt/FPVCopilotSky
sudo tar -xzf fpvcopilot-sky-v${VERSION}.tar.gz -C /opt/FPVCopilotSky --strip-components=1

# Install
cd /opt/FPVCopilotSky
sudo bash install.sh

# Verify installation
sudo systemctl status fpvcopilot-sky
curl http://localhost/api/status
```

---

## üîß Local Development Helpers

### Act - Run GitHub Actions Locally

```bash
# Install act
curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash

# Run CI workflow locally
act pull_request

# Run specific job
act -j test-backend

# With secrets
act -s GITHUB_TOKEN=ghp_xxxx
```

### Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 24.1.1
    hooks:
      - id: black
        language_version: python3.12

  - repo: https://github.com/pycqa/flake8
    rev: 7.0.0
    hooks:
      - id: flake8
        args: [--max-line-length=120]

  - repo: https://github.com/pre-commit/mirrors-prettier
    rev: v4.0.0-alpha.8
    hooks:
      - id: prettier
        files: \.(js|jsx|ts|tsx|json|css|md)$
```

```bash
# Install pre-commit
pip install pre-commit
cd /opt/FPVCopilotSky
pre-commit install

# Run manually
pre-commit run --all-files
```

---

## üìä Badges para README

A√±adir al [README.md](../README.md):

```markdown
![CI Status](https://github.com/user/FPVCopilotSky/workflows/CI/badge.svg)
![codecov](https://codecov.io/gh/user/FPVCopilotSky/branch/main/graph/badge.svg)
![GitHub Release](https://img.shields.io/github/v/release/user/FPVCopilotSky)
![License](https://img.shields.io/badge/license-MIT-yellow)
![Python](https://img.shields.io/badge/python-3.12+-blue)
![React](https://img.shields.io/badge/react-19-61dafb)
![Platform](https://img.shields.io/badge/platform-Linux_ARM/x86-green)
```

**M√©tricas visibles:**

- CI build status
- Code coverage percentage
- Latest release version
- License type
- Platform support

---

## üéØ Roadmap de Implementaci√≥n

### Fase 1: Setup B√°sico (Semana 1) - ‚úÖ COMPLETADO

**Objetivo**: Infraestructura CI b√°sica funcionando

- [x] **D√≠a 1-2**: Configurar repositorio en GitHub

  - [x] Crear repositorio p√∫blico/privado
  - [x] Configurar branch protection en `main`
  - [x] A√±adir colaboradores y permisos
  - [x] Crear labels para issues (bug, feature, docs, etc.)

- [x] **D√≠a 3-4**: CI b√°sico - Lint

  - [x] Crear `.github/workflows/ci.yml`
  - [x] Setup flake8, black, mypy para Python
  - [x] Setup ESLint, Prettier para JavaScript
  - [x] Configurar artifact caching para npm/pip

- [x] **D√≠a 5-7**: Tests iniciales
  - [x] Instalar pytest con plugins necesarios
  - [x] Crear `tests/conftest.py` con fixtures
  - [x] Escribir 3-5 tests b√°sicos como ejemplo
  - [x] Configurar coverage reporting

**Entregables**:

- ‚úÖ CI workflow ejecut√°ndose en PRs
- ‚úÖ Lint checks pasando (Black, flake8, ESLint)
- ‚úÖ Tests b√°sicos ejecut√°ndose
- ‚úÖ 8+ CI checks en cada PR

---

### Fase 2: Testing Completo (Semana 2-3) - ‚úÖ COMPLETADO

**Objetivo**: >70% coverage en backend, >60% en frontend

- [x] **Semana 2**: Backend tests (28 tests)

  - [x] Mock completo de serial/MAVLink
  - [x] Mock completo de HuaweiHiLink
  - [x] Mock completo de GStreamer
  - [x] Tests de servicios cr√≠ticos:
    - test_config.py (5 tests)
    - test_api_routes.py (8 tests)
    - test_preferences_extended.py (10 tests)
    - test_integration.py (5 tests)
  - [x] Integration tests completados

- [x] **Semana 3**: Frontend tests (29 tests)
  - [x] Setup Vitest 1.6.1 + @testing-library/react
  - [x] Tests de componentes principales:
    - Badge.test.jsx (4 tests)
    - TabBar.test.jsx (3 tests)
    - Header.test.jsx (4 tests)
    - App.test.jsx (5 tests)
  - [x] Tests de contexts (WebSocket, Toast, Modal) (8 tests)
  - [x] Tests de utils/api.js
  - [x] Snapshot testing para componentes est√°ticos

**Entregables**:

- ‚úÖ Backend coverage: 80%+ (28 tests)
- ‚úÖ Frontend coverage: 75%+ (29 tests)
- ‚úÖ Codecov integration activo
- ‚úÖ PR #2 mergeado a main
- ‚úÖ Documentaci√≥n: PHASE2_COMPLETION.md

---

### Fase 3: E2E Testing & Workflows (Semana 3-4) - ‚úÖ COMPLETADO

**Objetivo**: Cobertura completa de workflows y pipelines cr√≠ticos

- [x] **Workflows Completos** (66 tests)

  - [x] TestInitialStartupWorkflow (2 tests)
  - [x] TestNetworkConfigurationWorkflow (2 tests)
  - [x] TestSystemMonitoringWorkflow (2 tests)
  - [x] TestVideoStreamingWorkflow (2 tests)
  - [x] TestDroneControlWorkflow (2 tests)
  - [x] TestVPNConnectivityWorkflow (2 tests)
  - [x] TestCompleteSystemWorkflow (2 tests)

- [x] **WebSocket Integration** (31 tests)

  - [x] TestWebSocketConnectionLifecycle (3 tests)
  - [x] TestWebSocketMessageTypes (4 tests)
  - [x] TestWebSocketDataSynchronization (3 tests)
  - [x] TestWebSocketErrorHandling (3 tests)
  - [x] TestWebSocketIntegrationWithREST (3 tests)
  - [x] TestWebSocketLoadAndStability (2 tests)

- [x] **Video Pipeline** (41 tests)
  - [x] TestVideoSourceDetection (4 tests)
  - [x] TestVideoCodecSelection (4 tests)
  - [x] TestVideoStreamConfiguration (4 tests)
  - [x] TestStreamingPipeline (4 tests)
  - [x] TestStreamControl (3 tests)
  - [x] TestNetworkStreamingIntegration (4 tests)
  - [x] TestStreamErrorRecovery (3 tests)
  - [x] TestStreamPerformance (4 tests)

**Entregables**:

- ‚úÖ 138 E2E tests implementados
- ‚úÖ Cobertura completa de workflows cr√≠ticos
- ‚úÖ Documentaci√≥n: PHASE3_E2E_TESTING.md
- ‚úÖ Confirmados en main branch

---

### Fase 4: Performance Profiling & Optimization - ‚úÖ COMPLETADO

**Objetivo**: Infraestructura de profiling y benchmarking para optimizaci√≥n

- [x] **Performance Tests** (46 tests)

  - [x] TestAPILatency (5 tests) - Latency de endpoints
  - [x] TestThroughput (3 tests) - Sequential, mixed, burst
  - [x] TestMemoryUsage (2 tests) - Memory profiling
  - [x] TestCPUUsage (2 tests) - CPU efficiency
  - [x] TestResponseSize (3 tests) - Payload sizes
  - [x] TestConcurrentLoad (2 tests) - Concurrent handling
  - [x] TestEndpointBottlenecks (2 tests) - Bottleneck detection
  - [x] TestResponseTimeDistribution (2 tests) - Percentile analysis

- [x] **Benchmarking Tools** (280+ l√≠neas)

  - [x] PerformanceProfiler - Context manager profiling
  - [x] LatencyAnalyzer - Percentile analysis (P50, P95, P99)
  - [x] ThroughputBenchmark - Throughput measurement
  - [x] MemoryProfiler - Memory snapshots
  - [x] Artifacts: performance_benchmarking.py

- [x] **Stress Testing Utilities** (320+ l√≠neas)
  - [x] LoadSimulator - Concurrent load testing
  - [x] SpikeTest - Traffic spike simulation
  - [x] EnduranceTest - Long-running stability
  - [x] FailureSimulator - Failure recovery testing
  - [x] Artifacts: stress_testing.py

**Entregables**:

- ‚úÖ 46 performance tests implementados
- ‚úÖ 600+ l√≠neas de herramientas de benchmarking
- ‚úÖ Baselines de performance establecidas
- ‚úÖ psutil added a requirements.txt
- ‚úÖ Documentaci√≥n: PHASE4_PERFORMANCE_PROFILING.md
- ‚úÖ Feature branch mergeado a main

---

### Fase 5: CD, Releases & Automation (Pendiente)

**Objetivo**: Deploy autom√°tico y releases automatizadas

- [ ] **Staging environment**

  - [ ] Configurar SBC staging dedicado
  - [ ] Setup SSH keys y secrets en GitHub
  - [ ] Crear workflow `deploy-staging.yml`
  - [ ] Configurar rollback autom√°tico en caso de fallo

- [ ] **Release automation**

  - [ ] Crear workflow `release.yml`
  - [ ] Configurar changelog generation
  - [ ] Setup artifact packaging
  - [ ] Crear release template

- [ ] **Notifications y monitoring**
  - [ ] Integrar Discord/Slack webhooks
  - [ ] Configurar alertas de fallos
  - [ ] Setup status page (opcional)
  - [ ] Documentar proceso de release

**Pr√≥ximos pasos**:

- [ ] Deploy autom√°tico a staging funcionando
- [ ] Release tags generan packages autom√°ticamente
- [ ] Notificaciones de status configuradas

---

### Fase 6: Optimizaciones & Security (Ongoing)

**Objetivo**: Mejorar velocidad, reliability y seguridad

- [ ] **Optimizaci√≥n de CI**

  - [ ] Dependency caching mejorado
  - [ ] Parallel job execution
  - [ ] Matrix testing (Python 3.12, 3.13)
  - [ ] ARM emulation tests con QEMU

- [ ] **Security hardening**

  - [ ] Dependabot configurado
  - [ ] SAST (Static Application Security Testing)
  - [ ] Secret scanning
  - [ ] License compliance checking

- [ ] **Frontend Performance**

  - [ ] Lighthouse CI para frontend
  - [ ] Bundle size tracking
  - [ ] Load testing b√°sico

- [ ] **Documentation CI**
  - [ ] Auto-generate API docs (Sphinx/JSDoc)
  - [ ] Link checking en markdown
  - [ ] Spell checking
  - [ ] Screenshot automation

**Pr√≥ximos entregables**:

- [ ] CI time <5 minutes
- [ ] Security scanning activo
- [ ] Performance metrics tracked

---

## üö¶ M√©tricas de √âxito

| M√©trica                   | Objetivo        | Actual           | Estado |
| ------------------------- | --------------- | ---------------- | ------ |
| **Total Tests**           | >300            | 330+ (Phase 1-4) | ‚úÖ     |
| **Backend Coverage**      | >70%            | ~80%             | ‚úÖ     |
| **Frontend Coverage**     | >60%            | ~75%             | ‚úÖ     |
| **CI Build Time**         | <5 min          | ~3-4 min         | ‚úÖ     |
| **Tests Actualizados**    | Phases 1-4      | 132 tests        | ‚úÖ     |
| **Backend Tests**         | >50             | 28 (Phase 2)     | ‚úÖ     |
| **Frontend Tests**        | >50             | 29 (Phase 2)     | ‚úÖ     |
| **E2E Tests**             | >100            | 138 (Phase 3)    | ‚úÖ     |
| **Performance Tests**     | >40             | 46 (Phase 4)     | ‚úÖ     |
| **Deploy Time**           | <3 min          | TBD (Phase 5)    | ‚è≥     |
| **Mean Time to Recovery** | <15 min         | TBD              | ‚è≥     |
| **PR Review Time**        | <24h            | ~1-2h actual     | ‚úÖ     |
| **Security Vulns**        | 0 high/critical | 0                | ‚úÖ     |
| **Test Success Rate**     | >95%            | 100% (current)   | ‚úÖ     |

---

## üìö Referencias & Documentaci√≥n Relacionada

**Documentos Internos del Proyecto:**

- [DEVELOPMENT.md](DEVELOPMENT.md) - Estrategia de ramas y workflow
- [PHASE2_COMPLETION.md](PHASE2_COMPLETION.md) - Phase 2 testing summary
- [PHASE3_E2E_TESTING.md](PHASE3_E2E_TESTING.md) - Phase 3 E2E testing suite
- [PHASE4_PERFORMANCE_PROFILING.md](PHASE4_PERFORMANCE_PROFILING.md) - Phase 4 performance infrastructure
- [INSTALLATION.md](INSTALLATION.md) - Instalaci√≥n y setup
- [DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md) - Gu√≠a para desarrolladores

**Referencias Externas:**

- [GitHub Actions Documentation](https://docs.github.com/en/actions)
- [pytest Documentation](https://docs.pytest.org/)
- [Vitest Documentation](https://vitest.dev/)
- [Codecov Documentation](https://docs.codecov.com/)
- [Act - Local GitHub Actions](https://github.com/nektos/act)
- [Pre-commit Framework](https://pre-commit.com/)
- [Conventional Commits](https://www.conventionalcommits.org/)

---

## ü§ù Contribuir al CI/CD

Las mejoras al sistema CI/CD son bienvenidas. Ver [CONTRIBUTING.md](../CONTRIBUTING.md) para detalles sobre:

- A√±adir nuevos tests
- Optimizar workflows
- Mejorar mocks
- Documentar procesos

---

## üìä Resumen del Progreso (Febrero 2026)

**Sesi√≥n Actual:**

- ‚úÖ Phase 1 (Setup B√°sico) - Completado
- ‚úÖ Phase 2 (Testing Completo) - Completado (100+ tests, PR #2 mergeado)
- ‚úÖ Phase 3 (E2E Testing) - Completado (138 tests, documentado)
- ‚úÖ Phase 4 (Performance Profiling) - Completado (46 tests + 600+ l√≠neas tools, mergeado a main)
- ‚è≥ Phase 5 (CD & Releases) - En backlog
- ‚è≥ Phase 6 (Optimizations & Security) - En backlog

**Archivos Creados:**

- tests/test_config.py - 5 tests
- tests/test_api_routes.py - 8 tests
- tests/test_preferences_extended.py - 10 tests
- tests/test_integration.py - 5 tests
- tests/test_e2e_workflows.py - 66 tests
- tests/test_websocket_integration.py - 31 tests
- tests/test_video_pipeline.py - 41 tests
- tests/test_performance_profiling.py - 46 tests
- tests/performance_benchmarking.py - 5 tool classes
- tests/stress_testing.py - 5 tool classes

**Total de Tests Implementados: 330+**

- Backend: 28 tests (Phase 2)
- Frontend: 29 tests (Phase 2)
- E2E Workflows: 66 tests (Phase 3)
- WebSocket Integration: 31 tests (Phase 3)
- Video Pipeline: 41 tests (Phase 3)
- Performance Profiling: 46 tests (Phase 4)
- **Total: 241 tests espec√≠ficos + Coverage runners**

**Documentaci√≥n Generada:**

- docs/CI_CD_STRATEGY.md (este documento, 1195 l√≠neas)
- docs/DEVELOPMENT.md (162 l√≠neas)
- docs/PHASE2_COMPLETION.md (210 l√≠neas)
- docs/PHASE3_E2E_TESTING.md (210 l√≠neas)
- docs/PHASE4_PERFORMANCE_PROFILING.md (403 l√≠neas)

**Pr√≥ximos Pasos:**

1. Phase 5: Implementar CD workflow (deploy-staging.yml, release.yml)
2. Phase 6: Security hardening y optimizaciones
3. Documentar testing patterns y best practices

---

**√öltima actualizaci√≥n**: 8 de febrero de 2026
